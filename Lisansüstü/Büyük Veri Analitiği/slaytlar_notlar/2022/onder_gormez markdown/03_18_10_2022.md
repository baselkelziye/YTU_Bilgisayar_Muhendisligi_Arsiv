# 3. Week - 18 October 2022 Tuesday

# HADOOP
* Giden bir bilgisayar olduğundan otomatik olarak halledilebilir.
* Düzgün çalışan dağıtık sistemler.
* Bir veri default olarak Hadoop'ta 3 bilgsayarda birden tutulmaktadır. Bu da güvenliği sağlamaktadır.
* Amazon S3 platform like Google Drive

**TODO:** El yazısı ders notundaki çizimi buraya aktar.

Hive: Query Language
Riv: Scripting Language

* Üst seviyeden MapRecduce otomatik olarak değiştiriliyor. Ama bu işlem yavaş gerçekleşiyor.
* MapReduce: Paralel olarak veriyi işler. Java'da yazmak gerekiyor. Map ve Reduce ayrı ayrı yazılıyor.
* Hadoop < 2.0 no YARN, Hadoop > 2.0 have YARN
* Cascading is a interface, like java
* HBase is a NoSQL database. MapReduce vb. dönüşüm yapmadan direkt HDFS'e erişim ve işlemi sağlıyor.
* Günümüzde Spark çok daha yaygın kullanılmakta, lakin Hadoop ile benzer yapıya sahip.

**TODO:** El yazısı ders notundaki çizimi buraya aktar.

## HDFS Design
Name Node --> Master
Data Node --> Slave

Name Node stores meta data, #1 cluster.
Data Node stores data blocks. Name node must be more than once.

* Name node erişilemez olursa sistem erişilemez olur. Bunu engellemek için secondary name node kullanılıyor.
* Secondary name node is a stand-by copy of name node.
* Slave eklem ve çıkarma işlemlerinde sorun olmuyor. Verinin birden çok yerde kopyası olduğu için farklı data node ile işlemler devam ettirilebiliyor.

YARN: Kaynak yönetimi yapmayı sağlar.

Parity bit;
**TODO:** El yazısı ders notundaki çizimi buraya aktar.

## Data Ingestion
Ingestion: The process of taking food, drink, or another substance into the body by swallowing or absorbing it.

* Sqoop --> Structure data import/export RDMS
* Flume --> Unstructure data (csv file, ..) (Push System)
* Kafka --> Publish/Subscribe App (Pull based system) message broker

**TODO:** El yazısı ders notundaki çizimi buraya aktar.

* Kafka devamlı bilgi akışı sağlıyor. Örneğin futbol maçlarının sonuçlarının farklı (mobile, web, ...) ortamlara aktarılmasını sağlar.

## Streaming Engineers
* Apache Storm
* Apache Flink
* Apache Spark

## No SQL
* HBase
* Cassandra
* Bit Table

## Cluster / Resource Management / Orchestration
* YARN
* Apache Mesos (for large clusters)
* Kubernetes (for large clusters)

## Parallel Processing
* MapReduce (default)
* Spark (faster)
* Tez

### MapReduce
Map(...) --> data nodes
Shuffle: read/write data disk
Sort:
Reduce: Write on disk

### Tez

1- Read on disk
2- All intermediate are sort store
3- Final write on disk

MapReduce'un yavaşlığını Tez ile gideriyoruz. Tez ile sadece bir kez okuyup yazıyoruz. Zaten asıl kayıp zaman data okuma-yazma işleminde oluşuyor.

## Task Coordination / Flow / Schedule
* Oozie
Ör: 3 iş var. Önce hangisi başlayacak? Ne kadar zaman ayrılacak? ...

## Cluster Configuration Tool
Zookeeper: Genelde arka planda çalışır.

## User Interface (Not Default)
Apache: Arayüz sağlar. Tüm işlemler için.

## Working Principles
* Main Node needs more memory.
* Client code'u master'a yollar. Data transferi yok. Sadece kod yollanıyor. Data node üzerinde yollanan kod çalıştırlıp, output client'a döndürülüyor.
* Master sadece şurada çalıştır şeklinde söylüyor.

**TODO:** El yazısı ders notundaki çizimi buraya aktar.

TODO: HDFS working flow u incele.

**TODO:** El yazısı ders notundaki çizimi buraya aktar.

## YARN
Job Tracker'ı ikiye böldük.

* Task tracker
* Job tracker: Resource Management and Scheduling

* Resource Manager (#1 Cluster)
* Application Master --> (#1 Application per app) (Her job için 1 tane)

Architecture;
**TODO:** El yazısı ders notundaki çizimi buraya aktar.

Container: Kaynak
Application Master: İşleri Yöneten
Node Manager: Durum bilgisi (yaşayıp, yaşamama)
Resource Manager: Tüm işlemleri yönetiyor
