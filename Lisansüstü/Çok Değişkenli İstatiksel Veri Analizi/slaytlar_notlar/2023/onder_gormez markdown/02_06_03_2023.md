# 2. Week - 6 March 2023 Monday

## Geçen Hafta Tekrar
Örneklem nitelikleri;
* Olabildiğince büyük olması daha iyidir
* Genel popülasyonu temsil edebilecek şekilde olmalı, gerçeğe yakın olmalı
* Bağımsız ve rasgele seçilmeli

# Fundamentals of Matrix Algebra

## Matrix ve Vektör Gösterimi
A matrix is a rectangular array of numbers or symbolic


$$ Employees (e_i) => x_1 = age, x_2 = salary, x_3 = marriage, ... $$
yukarıdaki gibi kolonları olan bir tablo

$$ e_1 => 19, 5000, yes $$ 
$$ e_2 => 25, 10000, no $$


* tüm employee ler bir matrix olşturur.
* Her bir age, salary, marriage kolonları bir vektördür.

$$
\begin{bmatrix}
a_{11} & a_{12} & a_{13} & ... & a_{1n}\\
a_{21} & a_{22} & a_{23} & ... & a_{2n}\\
a_{21} & a_{32} & a_{33} & ... & a_{3n}\\
... & ... & ... & ... & a_{3n}\\
a_{n1} & a_{n2} & a_{n3} & ... & a_{nn}
\end{bmatrix} 
$$

**Diyagonal**: her bir rakamın bire bir arttığı durumda oluşan kısım. 
$$ a_{11}, a_{22}, a_{33}, ..., a_{nn} $$
* Vektörler **transpoze** da edilebilir. E' şeklinde gösterilir.
* Eşit matrix ler (4 x 4) **full matrix** dnir.

m: coefficient  
Y: target  
x: variable  
$$ \epsilon: epsilon $$

$$ Y = mx + \epsilon $$


## Toplama ve Çıkarma

* Pairwise toplama/çıkarma, karşılıklı değerler toplanır/çıkarılır.
* Yapılabilmesi için boyları eşit olmalıdır

## Çarpma ve Bölme

* Scalar bir değerle çarpımı, tüm elemanların bu değerle çarpımına eşittir.

A x B != B x A


* $$ A_{rc} X B_{mn} $$
*  yapılabilmesi için c = m olmalıdır.
* Bir matrix in kendisi ile transpozunun çarpımı bir scalar değerdir.

$$ 
X = 
\begin{bmatrix}
x_{1} & x_{2} & x_{3} & ... & x_{n}
\end{bmatrix} 
_{1xn}
$$

$$
X' = 
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
...\\
x_n
\end{bmatrix}_{nx1}
$$

$$ X * X' = x_1 * x_1 + ... + x_n * x_n $$

$$ \sum_{i=1}^n x_i^2 $$

## Özellikleri

Tensorflow ve diğer makine öğrenmesi kütüphaneleri arka planda matrix hesaplamaları ile işlerini gerçekleştiriyor.

**Diyagonal Matris**: sadece karşılıklı eşit değerlerin sıfırdan farklı olduğu, diğer değerlerin 0 olduğu matrise denir.

$$
\begin{bmatrix}
a_{11} & 0 & 0 & ... & 0\\
0 & a_{22} & 0 & ... & 0\\
0 & 0 & a_{33} & ... & 0\\
... & ... & ... & ... & ...\\
0 & 0 & 0 & ... & a_{nn}
\end{bmatrix} 
$$

* Diyagonal matris simetriktir. Fakat her simetrik matris diyagonal matris değildir.
* **Identity matris**: Birim matris tir. Diyagonal değerler 1, diğerleri sıfırdır. 
* Zero Vector/Matrix: tüm değerleri sıfırdır

**Linear Dependency**: Bir satır başka bir satırın tam katı olarak gösterilebiliyorsa linear dependent özelliği oluyor.

$$
A = 
\begin{bmatrix}
1 & -3\\
-4 & 12
\end{bmatrix}
_{2x2}
$$
Birinci satır ile 2. birbirinin katı (-4)

**Rank of a matrix**: Linear olarak bağımlı olmayan vektör sayısına eşittir.
A matrisi katı olmayan 2 - 1 rank(A) = 1 (boyut - bağlı olan sayısı)


$$
B = 
\begin{bmatrix}
4 & -3\\
4 & 12
\end{bmatrix}
_{2x2}
$$
linear independent olduğu için rank(B) = 2 boyutuna eşittir.

**Full rank**: Tüm satırlar birbirinden bağımsız ile full rank olur ve rank matris boyutuna eşit olur.

## Uzaklık ve Diğerleri

Açı (alfa) büyüdükçe benzerlik azalıyor.
similatiry
Sim(p1, P2) = Sim (p2, P3)

d: distance
d(P1, P2) > d(P2,P3)

2 vektör ortagonal ise yani birbirine dik ise benzerlik hiç yok denir.
cos (alfa = 90) = 0
cos (alfa = 0) = 1 yani 


boyutu: transpozu ile kendisinin çarpımına eşittir.
mutlak(p1) = karekök (x1^2 + x2^2) = karekök(p1' x p1)

Sim(p1, p2) = cos(tetha) = P1.P2 / (karekök(p1' x p1) * karekök(p2' x p2))

# Pearson Correlation


![](https://editor.analyticsvidhya.com/uploads/39170Formula.JPG)
## Inverse of Matrixes

A^-1 x A = I birim vektör

* Bir matrisin tersi olabilmesi için full rank (all rows linarly independent) ve kare matris olmalıdır.  
ve
det(A) != 0 olmalı

$$
A = 
\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
_{2x2}
$$

ise matrisin tersi

$$
A^-1 = \dfrac{1}{|A|} * 
\begin{bmatrix}
d & -b\\
-c & a
\end{bmatrix}
_{2x2}
$$

full rank değilse A nın tersi yoktur. Çünkü sıfır çıkacak determinantı

NOTE: Useful Matrix Results slaytında kaldık.
