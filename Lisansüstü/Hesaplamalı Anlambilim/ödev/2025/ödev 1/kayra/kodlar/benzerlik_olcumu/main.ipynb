{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giriş işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "is_colab = False # eğer colab kullanıyorsanız True yapın\n",
    "if is_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = \"/content/drive/MyDrive/gsm8k-tr-semantik-analiz/benzerlik_olcumu\"\n",
    "else:\n",
    "    root_path = os.getcwd()  # dosyanın bulunduğu klasör\n",
    "print(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerekli kütüphaneleri yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Gereksinimler dosyasının yolu\n",
    "requirements_path = os.path.join(root_path, \"gereksinimler.txt\")\n",
    "\n",
    "# Gereksinimler yükleniyor\n",
    "try:\n",
    "    print(\"Gereksinimler yükleniyor...\")\n",
    "    subprocess.run(\n",
    "        [\"pip\", \"install\", \"-r\", requirements_path],\n",
    "        check=True,\n",
    "        stdout=subprocess.DEVNULL,  # Çıktıyı gizler\n",
    "        stderr=subprocess.DEVNULL   # Hataları gizler\n",
    "    )\n",
    "    print(\"Gereksinimler başarıyla yüklendi.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Gereksinimler yüklenirken hata oluştu.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Dosya bulunamadı: {requirements_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dosya dizinini sistem yoluna ekle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(root_path)\n",
    "print(f\"'{root_path}' kütüphane arama yoluna eklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yerel kod dosyalarını içe aktar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dosya_islemleri import (load_model, load_dataset, read_embedding_from_file, read_probability_from_file, read_top1_top5_results_json)\n",
    "from benzerlik_islemleri import calculate_and_save_similarity_scores, get_and_save_all_top5_matches\n",
    "from gorsellestir import save_tsne_png, plot_two_tsne_results, plot_t1_t5_scores\n",
    "from gomme_islemleri import (calculate_and_save_raw_embeddings_from_dataset, tsne_sonuc_olustur, get_multi_token_embeddings, \n",
    "                             apply_multi_tsne)\n",
    "from top_islemleri import calculate_top1_top5_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cihaz tipini al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# cihaz tipini al\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Kullanılan cihaz tipi: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelleri tanımla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"intfloat/multilingual-e5-base\",                                # 278M  - 81\n",
    "    \"ibm-granite/granite-embedding-107m-multilingual\",              # 107M  - 48\n",
    "    \"intfloat/multilingual-e5-small\",                               # 118M  - 36\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",  # 118M  - 62\n",
    "    \"shibing624/text2vec-base-multilingual\",                        # 118M  - 77 \n",
    "    \"ytu-ce-cosmos/turkish-colbert\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesini yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri kümesi yükleniyor\n",
    "df = load_dataset()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_prefix(model_name):\n",
    "    return model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gömme (embedding) hesaplama işleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her model için\n",
    "for i, model_name in enumerate(model_names):\n",
    "        save_prefix = get_save_prefix(model_name)\n",
    "        model, tokenizer = load_model(model_name, device_type=device)\n",
    "        calculate_and_save_raw_embeddings_from_dataset(model, tokenizer, df, save_prefix, device) # sonuçlar embeddings klasörüne kaydedilir\n",
    "        print(f\"Embeddingler hesaplandı ve kaydedildi: {model_name} ({i+1}/{len(model_names)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gömmeleri görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Değiştirilebilir\n",
    "import random\n",
    "examples = []\n",
    "for i in range(10):\n",
    "    random_index = random.randint(0, len(df) - 1)\n",
    "    examples.append(random_index)\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model, tokenizer = load_model(model_name, device_type=device)\n",
    "    save_prefix = get_save_prefix(model_name)\n",
    "    raw_embeddings = read_embedding_from_file(save_prefix)\n",
    "    tsne_res = tsne_sonuc_olustur(raw_embeddings, save_prefix)  # sonuçlar tsne_results klasörüne kaydedilir (json olarak)\n",
    "    save_tsne_png(tsne_res, save_prefix, title=model_name, q_color=\"green\", a_color=\"blue\")                        # sonuçlar tsne_results klasörüne kaydedilir\n",
    "    for idx in examples:\n",
    "        example_item = df.iloc[idx]\n",
    "        # bu kısım örnek amaçlı her model için ilk soru ve cevabın gömmelerini görselleştirir\n",
    "        question_multi_token_embeddings = get_multi_token_embeddings(model, tokenizer, example_item[\"question\"], device)\n",
    "        question_multi_tsne = apply_multi_tsne(question_multi_token_embeddings)\n",
    "        answer_multi_token_embeddings = get_multi_token_embeddings(model, tokenizer, example_item[\"answer\"], device)\n",
    "        answer_multi_tsne = apply_multi_tsne(answer_multi_token_embeddings)\n",
    "        plot_two_tsne_results(question_multi_tsne, answer_multi_tsne, save_prefix, idx, label1=\"Soru\",\n",
    "                                label2=\"Cevap\", color1=\"green\", color2=\"blue\", title=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gömmelere göre benzerlik skoru hesaplama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model_name in enumerate(model_names):\n",
    "    save_prefix = get_save_prefix(model_name)\n",
    "    raw_embeddings = read_embedding_from_file(save_prefix)\n",
    "    calculate_and_save_similarity_scores(raw_embeddings, save_prefix, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benzerlik sonuçlarına göre top1-top5 doğruluk oranlarını hesaplama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model_name in enumerate(model_names):\n",
    "    save_prefix = get_save_prefix(model_name)\n",
    "    similarity_scores = read_probability_from_file(save_prefix)\n",
    "    get_and_save_all_top5_matches(similarity_scores, save_prefix)           # sonuçlar top1_top5_results klasörüne kaydedilir (json olarak)\n",
    "    print(f\"Benzerlikler hesaplandı ve kaydedildi: {model_name} ({i+1}/{len(model_names)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top1 - Top5 doğruluk oranlarını görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_top_scores = []\n",
    "question_top_scores = []\n",
    "for i, model_name in enumerate(model_names):\n",
    "    save_prefix = get_save_prefix(model_name)\n",
    "    question_results = read_top1_top5_results_json(save_prefix, is_question_to_answer=True)\n",
    "    answer_results = read_top1_top5_results_json(save_prefix, is_question_to_answer=False)\n",
    "    question_top1_top5 = calculate_top1_top5_scores(question_results, model_name)\n",
    "    answer_top1_top5 = calculate_top1_top5_scores(answer_results, model_name)\n",
    "    question_top_scores.append(question_top1_top5)\n",
    "    answer_top_scores.append(answer_top1_top5)\n",
    "    print(f\"Top1 ve Top5 skorları hesaplandı: {model_name} ({i+1}/{len(model_names)})\\r\")\n",
    "plot_t1_t5_scores(answer_top_scores, question_top_scores, question_color=\"green\", answer_color=\"blue\")                                   # sonuç top1_top5_results klasörüne kaydedilir (png olarak)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
