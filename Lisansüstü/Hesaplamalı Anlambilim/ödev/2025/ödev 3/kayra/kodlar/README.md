# ğŸ§‘â€ğŸ”¬  Turkish GPT-2 Fine-Tuning  

Bu depo turkish-gpt-2'nin ince ayarÄ± iÃ§in kod, veri ve dokÃ¼mantasyonu iÃ§erir.  
AmaÃ§; iki TÃ¼rkÃ§e GPT-2 modelini (*medium & large*) GPT-4o ve DeepSeek Ã§Ä±ktÄ±larÄ±yla **instruction fine-tuning** edip,
50 adet Ã¶zgÃ¼n â€œsÄ±namaâ€ sorusu Ã¼zerinden karÅŸÄ±laÅŸtÄ±rmaktÄ±r.  
TÃ¼m kodlar, **Google Colabâ€™da sorunsuz Ã§alÄ±ÅŸacak** ÅŸekilde otomatik ortam kontrolleri (`is_colab()`) iÃ§erir.

## ğŸ“‚ Dizin / Dosya YapÄ±sÄ±

| Yol / Dosya | AÃ§Ä±klama |
|-------------|----------|
| `tanÄ±m.pdf` | Ã–dev metni & teslim ÅŸartlarÄ±. |
| `train.ipynb`  | 4 adet LoRA-tabanlÄ± model eÄŸitimi: <br>â–¸ Veri hazÄ±rlama <br>â–¸ Tokenizer / model yÃ¼kleme <br>â–¸ Quantization (4-/8-/16-bit) <br>â–¸ EÄŸitim dÃ¶ngÃ¼sÃ¼ & checkpoint yÃ¶netimi. |
| `sinama.ipynb` | Ä°nference / karÅŸÄ±laÅŸtÄ±rma betiÄŸi: <br>â–¸ EÄŸitilen modelleri tek tek yÃ¼kler <br>â–¸ `sinama_sorulari.csv` Ã¼zerindeki cevaplarÄ± Ã¼retir <br>â–¸ SonuÃ§larÄ± `/sonuclar` klasÃ¶rÃ¼ne kaydeder. |
| `sinama_sorulari.csv` | 50 adet deneme sorusu. |
| `soru_cevap.csv` | GPT-4o & DeepSeek yanÄ±tlarÄ±nÄ± iÃ§eren asÄ±l fine-tuning veri seti (Google Sheetsâ€™ten dÄ±ÅŸa aktarÄ±lÄ±r). |
| `README.md` | Bu dosya. |
| `sonuclar/` | Her model iÃ§in oluÅŸturulan cevap CSVâ€™leri. |

---

## ğŸ” `sinama_sorulari.csv` DetaylarÄ±  

| SÃ¼tun | Ä°Ã§erik |
|-------|--------|
| `soru`   | Sorunun tam metni (TÃ¼rkÃ§e). |
| `zorluk` | 1: Kolay &nbsp; 2: Orta &nbsp; 3: Zor |

Dosya; eÄŸitim verisinde **yer almayan** elle oluÅŸturduÄŸum 50 sorudan oluÅŸur ve model genellemesini sÄ±namak iÃ§in kullanÄ±lÄ±r.  
`sinama.ipynb`, bu CSVâ€™yi okuyup her soruyu prompt biÃ§imine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:

```python
<SORU> â€¦ </SORU> <CEVAP> <|endoftext|>
```
Model EOS Ã¼rettiÄŸinde durdurulur, bÃ¶ylece yalnÄ±zca yanÄ±t kÄ±smÄ± kaydedilir.

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Google Colab)

1. Depoyu Colabâ€™a klonlayÄ±n  
   ```bash
   !git clone https://github.com/kaayra2000/turkish_gpt2_finetuning.git
   %cd odev-instruction-finetune
   ```
1. Gereksinimleri yÃ¼kleyin

1. EÄŸitimi baÅŸlatÄ±n
    train.ipynb dosyasÄ±nÄ± aÃ§Ä±n ve `Runtime` > `Run all` ile Ã§alÄ±ÅŸtÄ±rÄ±n.

1. EÄŸitimi tamamladÄ±ktan sonra `sinama.ipynb` dosyasÄ±nÄ± aÃ§Ä±n ve `Runtime` > `Run all` ile Ã§alÄ±ÅŸtÄ±rÄ±n.
    Ã‡Ä±ktÄ±lar `sonuclar/` klasÃ¶rÃ¼ne kaydedilecektir.

## ğŸ‹ï¸â€â™‚ï¸ EÄŸitim AyrÄ±ntÄ±larÄ±

- **Model**: `turkish-gpt2-medium` ve `turkish-gpt2-large` (Hugging Face)
- **LoRA**: `peft` kÃ¼tÃ¼phanesi ile ince ayar yapÄ±ldÄ±.
- **Veri KÃ¼mesi**: `soru_cevap.csv` (GPT-4o ve DeepSeek yanÄ±tlarÄ±)
- **EÄŸitim SÃ¼resi**: 1-2 saat * model sayÄ±sÄ± (Google Colab Pro)

## ğŸ§ª SÄ±nama AyrÄ±ntÄ±larÄ±

- **Model**: `turkish-gpt2-medium` ve `turkish-gpt2-large` (Hugging Face)
- **SÄ±nama SorularÄ±**: `sinama_sorulari.csv` (50 adet Ã¶zgÃ¼n soru)
- **SÄ±nama SÃ¼resi**: 1-2 saat * model sayÄ±sÄ± (Google Colab Pro)
- **SonuÃ§lar**: `sonuclar/` klasÃ¶rÃ¼nde her model iÃ§in ayrÄ± CSV dosyalarÄ±.