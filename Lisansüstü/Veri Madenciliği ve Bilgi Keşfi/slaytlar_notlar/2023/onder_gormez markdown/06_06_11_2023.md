# 6. Week - 6 November 2023 Monday

Haftya 13 Kasım da sınav yapacağız.

# The Bayesian Theorem

P(Ci|X) = P(X|Ci) * P(Ci) / P(X)

P(Ci): Number of samples in Ci / Total number of samples

* Naive assumption of conditional indepence between attributes made.

* Dataset içerisinde nümerik bir özniteliğe sahipsem, örneğin yaş gibi. 23 yaş olma olasılı gibi bir şeyde nasıl davranmam gerekiyor?
  * Benim aklıma direkt olarak, yaş aralıklarına ayırmak geldi. Örneğin 0-10 yaş arası, 10-20 yaş arası gibi. Bu şekilde bir kategorilendirme yapılabilir.
  * Kategorilendirme sonrası bir sınıflandırma ve tahminleme yapılabilir.
* Dataset içerisinde hiç olmayan bir değere sahipsem, örneğin araç listesinde hiç truck yok ama truck için bir tahmin yapmam gerekiyor. Nasıl davranmam gerekiyor?
  * Truck insurance yapılacak olsa risk durumu high olarak değerlendirilir bence. Çünkü çok pahalı ve sürekli seyahat eden bir araç olduğu için.
  * Bu nedenle truck için risk durumu high olarak değerlendirilebilir.

* Yukarıdaki 1. durumda yapılması gerekenler;

Normal dağılımda, ortalama (mean) ve standart sapmasını (standard deviation) biliyorum. Bu bilgileri kullanarak, 23 yaş için bir olasılık hesaplayabilirim.

P(Age = 23 | Normal Distribution) = (1 / (sqrt(2 * pi) * sigma^2)) * e ^ (-(23 - mean)^2 / (2 * std^2))

* Yukarıdaki 2. durum için yapılması gerekenler;

Laplace adjustment yapılabilir. Bu durumda, truck için risk durumu bulunabilir.
  * Tüm olasılık değerleri 1 arttırılır.

# Class Imbalance Problem
2 tane Supervised Learning algoritması öğrendik.
* Veride bir sınıftan çok fazla örnek varken, diğer tarafta çok örnek yoktur. Biz bu çok az olan kısmı yakalamaya çalışıyoruz.
  * Credit card fraud: Çok fazla normal işlem varken, fraud işlem çok azdır.
  * Intrusion detection: Çok fazla normal işlem varken, intrusion işlem çok azdır.
  * Defective products in manufacturing: Çok fazla normal ürün varken, defected ürün çok azdır.
* Bu durumda, öğrenme algoritması, çok fazla örneğe sahip olan sınıfı daha iyi öğrenirken, diğer sınıfı öğrenemeyebilir.

* Evaluation measures such as accuracy is not well-suited for imbalanced class
* Precision and recall are better suited for imbalanced class

# Confusion Matrix
Yukardaki sorunların üzerinden gelebilmek için class confusion matrix hazırlamamız gerekir.

Actual Class ve Predicted Class tam ortada merge edilmiş yerleri temsil ediyor aslında. Markdown da tabloda yapılamadı.

|              |             | Predicted Class |            |
|:------------:|:-----------:|:---------------:|:----------:|
|              |             |   Class = Yes   | Class = No |
| Actual Class | Class = Yes |        a        |      b     |
|              |  Class = No |        c        |      d     |



a: TP (True Positive)  
b: FN (False Negative)  
c: FP (False Positive)  
d: TN (True Negative)  

Accuracy = (TP + TN) / Total

* Precision ve recall ın harmonik ortalaması (F-measure) bazı durumlarda daha iyidir.

Precision (p) = a / (a + c)

Recall (r) = a / (a + b)

F-measure (F) = 2 * r * p / (r + p)

Fraud detection yapacaksan fraud lar positive olarak algılanmalıdır.
* Bulmaya çalıştığımız şey her zaman positive olarak değerlendirilir.
* Covid de positive demek covid olmuşsun demektir.
* Pozitifler her zaman rare class yani nadir görülen class oluyor.

# ROC (Receiver Operating Characteristic) Curve
* True Positive Rate (TPR) = Recall = a / (a + b)
* False Positive Rate (FPR) = c / (c + d)

Cost Matrix: Bir sınıflayıcının yanlış hesapladığı değerlerin maliyetini gösteren matris.

# Sampling-based Approach

Modify the training set
* Undersample the majority class
* Oversample the minority/rare class

# Midterm/Vize

TODO: Vize haftaya
* Genelde 4 tane soru soruyor.
* Tanım sorusu sormaz
* Küçük problemler
* Karar ağacı çizin
* Bayes ile classification yapın
* Ne kadar doğru ne kadar yanlış precision, recall hesaplatabilir. 5 sınıflı olabilir.
* Hesap makinesi ile gelin
* Logaritma 2 tabanı ve e üzeri nasıl hesaplanır bunu öğrenin
* DecisionTree'den kesin soru gelir