{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import random, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model_id = \"ytu-ce-cosmos/Turkish-Gemma-9b-T1\"\n",
    "topics=[\n",
    "    \"Tarih\", \"Coğrafya\", \"Fizik\", \"Kimya\", \"Biyoloji\", \"Edebiyat\", \"Felsefe\", \n",
    "    \"Teknoloji\", \"Yapay Zeka\", \"Psikoloji\", \"Sosyoloji\", \"Ekonomi\", \"Sanat\", \n",
    "    \"Müzik\", \"Sinema\", \"Spor\", \"Astronomi\", \"Matematik\", \"Tıp\", \"Mühendislik\",\n",
    "    \"Mitoloji\", \"Doğa\", \"Hayvanlar Alemi\", \"Gastronomi\", \"Mimari\"\n",
    "]\n",
    "\n",
    "main_topic = \"Genel Kültür\"\n",
    "dataset = []\n",
    "question_count = 500\n",
    "BATCH_SIZE = 10\n",
    "num_batches = question_count // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(generator_model_id)\n",
    "\n",
    "generator_model = AutoModelForCausalLM.from_pretrained(\n",
    "    generator_model_id,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=num_batches) as pbar:\n",
    "    for i in range(num_batches):\n",
    "        \n",
    "        current_topic = random.choice(topics)\n",
    "        \n",
    "        prompt = (\n",
    "            f\"Bana {current_topic} hakkında {BATCH_SIZE} adet {main_topic} sorusu yaz. \"\n",
    "            f\"Yazdığın her soru için 1 adet iyi cevap (doğru ve detaylı) ve 1 adet kötü cevap (yanlış veya saçma) yaz. \"\n",
    "            f\"Format tam olarak şu şekilde olsun ve başka bir şey yazma:\\n\\n\"\n",
    "            f\"Q1: Soru cümlesi buraya\\n\"\n",
    "            f\"A1: İyi cevap buraya\\n\"\n",
    "            f\"A2: Kötü cevap buraya\\n\"\n",
    "            f\"Q2: Soru cümlesi buraya...\\n\"\n",
    "            f\"A1: ...\\n\"\n",
    "            f\"A2: ...\\n\"\n",
    "            f\"(Hepsini bu formatta alt alta yaz)\"\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(generator_model.device)\n",
    "\n",
    "        terminators = [\n",
    "            tokenizer.eos_token_id,\n",
    "            tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "        ]\n",
    "\n",
    "        outputs = generator_model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=4096,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.7 + (i * 0.01),\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "\n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        raw_text = tokenizer.decode(response, skip_special_tokens=True).strip()\n",
    "\n",
    "        raw_text = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL).strip()\n",
    "\n",
    "        pattern = r\"Q\\d+:\\s*(.*?)\\s*A1:\\s*(.*?)\\s*A2:\\s*(.*?)(?=Q\\d+:|$)\"\n",
    "        matches = re.findall(pattern, raw_text, re.DOTALL)\n",
    "\n",
    "        for match in matches:\n",
    "            question, good_ans, bad_ans = match\n",
    "            \n",
    "            entry = {\n",
    "                \"Konu\": current_topic,\n",
    "                \"Soru\": question.strip(),\n",
    "                \"Iyi_Cevap\": good_ans.strip(),\n",
    "                \"Kotu_Cevap\": bad_ans.strip()\n",
    "            }\n",
    "            \n",
    "            if entry[\"Soru\"] not in [x[\"Soru\"] for x in dataset]:\n",
    "                dataset.append(entry)\n",
    "                pbar.update(1)\n",
    "\n",
    "        if len(dataset) % 20 == 0 and len(dataset) > 0:\n",
    "            print(f\"\\nSon eklenen: {dataset[-1]['Soru']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95159dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "print(f\"\\nİşlem tamamlandı! Toplam {len(df)} soru üretildi.\")\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"soru_cevap_dataset_500.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
